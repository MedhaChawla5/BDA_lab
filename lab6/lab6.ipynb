{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d4a745f-c085-4086-8081-0ca666097a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n",
      "+-------+-----------------+------------+------------------+-------------+------------------+--------------+-----------------+------------+-------------------+-------+------------------+-----------------+-----------------+--------------+------+\n",
      "|summary|              age|   workclass|            fnlwgt|    education|     education_num|marital_status|       occupation|relationship|               race|    sex|      capital_gain|     capital_loss|   hours_per_week|native_country|income|\n",
      "+-------+-----------------+------------+------------------+-------------+------------------+--------------+-----------------+------------+-------------------+-------+------------------+-----------------+-----------------+--------------+------+\n",
      "|  count|             8601|        8601|              8601|         8601|              8601|          8601|             8601|        8601|               8601|   8601|              8601|             8601|             8601|          8601|  8601|\n",
      "|   mean|38.44959888385071|        NULL| 190405.3108940821|         NULL|10.074758748982676|          NULL|             NULL|        NULL|               NULL|   NULL|1049.5452854319265|89.71607952563656|40.50447622369492|          NULL|  NULL|\n",
      "| stddev|13.57487590896283|        NULL|106337.00940533858|         NULL| 2.541445526330006|          NULL|             NULL|        NULL|               NULL|   NULL| 7240.697280750416|403.9094831055375| 12.2589221313114|          NULL|  NULL|\n",
      "|    min|               17|           ?|           19302.0|         10th|               1.0|      Divorced|                ?|     Husband| Amer-Indian-Eskimo| Female|               0.0|              0.0|              1.0|             ?| <=50K|\n",
      "|    max|               90| Without-pay|         1226583.0| Some-college|              16.0|       Widowed| Transport-moving|        Wife|              White|   Male|           99999.0|           3004.0|             99.0|    Yugoslavia|  >50K|\n",
      "+-------+-----------------+------------+------------------+-------------+------------------+--------------+-----------------+------------+-------------------+-------+------------------+-----------------+-----------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"IncomePrediction\").getOrCreate()\n",
    "\n",
    "# Load dataset into PySpark DataFrame\n",
    "df = spark.read.csv(\"data.csv\", header=False, inferSchema=True)\n",
    "\n",
    "# Rename columns for better understanding\n",
    "df = df.withColumnRenamed(\"_c0\", \"age\")\\\n",
    "       .withColumnRenamed(\"_c1\", \"workclass\")\\\n",
    "       .withColumnRenamed(\"_c2\", \"fnlwgt\")\\\n",
    "       .withColumnRenamed(\"_c3\", \"education\")\\\n",
    "       .withColumnRenamed(\"_c4\", \"education_num\")\\\n",
    "       .withColumnRenamed(\"_c5\", \"marital_status\")\\\n",
    "       .withColumnRenamed(\"_c6\", \"occupation\")\\\n",
    "       .withColumnRenamed(\"_c7\", \"relationship\")\\\n",
    "       .withColumnRenamed(\"_c8\", \"race\")\\\n",
    "       .withColumnRenamed(\"_c9\", \"sex\")\\\n",
    "       .withColumnRenamed(\"_c10\", \"capital_gain\")\\\n",
    "       .withColumnRenamed(\"_c11\", \"capital_loss\")\\\n",
    "       .withColumnRenamed(\"_c12\", \"hours_per_week\")\\\n",
    "       .withColumnRenamed(\"_c13\", \"native_country\")\\\n",
    "       .withColumnRenamed(\"_c14\", \"income\")\n",
    "\n",
    "# Show basic statistics and information\n",
    "df.printSchema()\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a396af6d-06c6-4f07-a036-c867f03fd983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|income_index|\n",
      "+--------------------+------------+\n",
      "|[39.0,77516.0,13....|         0.0|\n",
      "|(14,[0,1,2,5,6,7,...|         0.0|\n",
      "|(14,[0,1,2,5,8,9,...|         0.0|\n",
      "|(14,[0,1,2,5,7,9,...|         0.0|\n",
      "|[28.0,338409.0,13...|         0.0|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Handling missing values\n",
    "# Dropping rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Handling categorical features using StringIndexer\n",
    "categorical_columns = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'income']\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in categorical_columns]\n",
    "\n",
    "# Assemble features into a feature vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'] + [col+\"_index\" for col in categorical_columns[:-1]],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# Create a pipeline for preprocessing\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "df_prepared = pipeline.fit(df_clean).transform(df_clean)\n",
    "\n",
    "# Show the prepared dataset with features column\n",
    "df_prepared.select(\"features\", \"income_index\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6623be86-612e-4808-aaaa-40d0b18cb90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+\n",
      "|            features|income_index|prediction|\n",
      "+--------------------+------------+----------+\n",
      "|[17.0,110998.0,10...|         0.0|       0.0|\n",
      "|[17.0,139183.0,6....|         0.0|       0.0|\n",
      "|[17.0,158762.0,6....|         0.0|       0.0|\n",
      "|[17.0,258872.0,7....|         0.0|       0.0|\n",
      "|[17.0,182070.0,7....|         0.0|       0.0|\n",
      "+--------------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"income_index\", featuresCol=\"features\", maxBins=45)\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Show sample predictions\n",
    "predictions.select(\"features\", \"income_index\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "195794eb-4f9d-4bc7-b0a6-ff2dbb9fa55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.84\n",
      "Test Precision: 0.84\n",
      "Test Recall: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"income_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"income_index\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"income_index\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "# Print accuracy, precision, and recall\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Test Precision: {precision:.2f}\")\n",
    "print(f\"Test Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0ad86-6436-449d-84bc-f1770ccb4767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
